{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab 09 - Model Selection\n",
    "\n",
    "Throughout the course we have encountered many hypothesis classes that are in-fact sets of hypothesis classes characterized by some hyper-parameter. We have seen that often this hyper-parameter can be seen as a tuning parameter over the bias-variance trade-off graph\n",
    "1. When choosing the number of neighbors $k$, in the $k$-NN classifier, we are contronling how complex are the hypotheses of this class.\n",
    "2. When choosing the max depth $d$ of decision trees, we are controling how complex are the hypotheses of this class.\n",
    "3. When choosing $\\lambda$ the regularization parameter of the Lasso or Ridge regressions we are controling how complex are the hypotheses of this class.\n",
    "\n",
    "Therefore, a key question is, how to correctly choose these parameters, or in other words how to select our preferred model in each set of hypothesis classes. To answer this question we will investigate 3 different ways of model selection based on \n",
    "1. the train set\n",
    "2. a validation set\n",
    "3. using cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "from utils import *\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this end we will use the South Africa heart disease dataset which is comprised of 462 records of patients which have (`chd=0`) or doesn't have (`chd=1`) the disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/SAheart.data\", header=0, index_col=0).sort_values('chd')\n",
    "df.famhist = df.famhist == \"Present\"\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "X_train, y_train, X_test, y_test = train.loc[:, train.columns != 'chd'].values, train[\"chd\"].values, test.loc[:, test.columns != 'chd'].values, test[\"chd\"].values\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection Based On ERM\n",
    "\n",
    "We begin with the simplest approach for selecting a model out of a set of possible models. We fit a $k$-NN classifier for different values of $k$, from $1$ to $40$, and select the classifier that achieved the lowest training error. \n",
    "\n",
    "As seen in Figure 1, the selected classifier is the one where we predict for each point based on the single closest training point. Since we are evaluating the results based on the training set, each point in the \"test\" (that is, the training set) is closest to itself, and therefore is given its own response.\n",
    "\n",
    "Though this approach yields a zero training error, we can see that for this dataset the test error is $0.4$. Thus, our classifier is heavily overfitted and does not general well to new datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = list(range(1, 40, 2))\n",
    "\n",
    "# Train and evaluate models for all values of k\n",
    "train_errors, test_errors = [], []\n",
    "for k in k_range:\n",
    "    model = KNeighborsClassifier(k).fit(X_train, y_train)\n",
    "    train_errors.append(1 - model.score(X_train, y_train))\n",
    "    test_errors.append(1 - model.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# Select model with lowest training error\n",
    "min_ind = np.argmin(np.array(train_errors))\n",
    "selected_k = np.array(k_range)[min_ind]\n",
    "selected_error = train_errors[min_ind]\n",
    "\n",
    "\n",
    "# Plot train- and test errors as well as which model (value of k) was selected\n",
    "go.Figure([go.Scatter(name='Train Error', x=k_range, y=train_errors, mode='markers+lines', marker_color='rgb(152,171,150)'), \n",
    "           go.Scatter(name='Test Error', x=k_range, y=test_errors, mode='markers+lines', marker_color='rgb(25,115,132)'),\n",
    "           go.Scatter(name='Selected Model', x=[selected_k], y=[selected_error], mode='markers', marker=dict(color='darkred', symbol=\"x\", size=10))])\\\n",
    "    .update_layout(title=r\"$\\text{(1) }k\\text{-NN Errors - Selection By ERM}$\", \n",
    "                   xaxis_title=r\"$k\\text{ - Number of Neighbors}$\", \n",
    "                   yaxis_title=r\"$\\text{Error Value}$\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection Based On A Validation Set\n",
    "\n",
    "For the next approach we follow the following scheme:\n",
    "1. Split training set into a training portion and a validation portion.\n",
    "2. Train models over training portion.\n",
    "3. Evaluate models over validation set and choose the one with the lowest error over the validation set.\n",
    "\n",
    "Since evaluation over the validation set provides an unbiased estimator of the generalization error (see proof in course book), this approach approximates the unknown generalization error and aims to select the model that we assume to perform best by that error.\n",
    "\n",
    "As evident by Figure 2, we do not select anymore the model where $k=1$ and instead choose the model where $k=25$. We can see that for all values of $k$ the validation- and test errors are similar, empirically showing how these independent sets can provide an unbiased estimation of the generalization error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training set into training- and validation sets\n",
    "n = int(X_train.shape[0]*0.5)\n",
    "X_train_smaller, y_train_smaller = X_train[:n], y_train[:n]\n",
    "X_val, y_val = X_train[n:], y_train[n:]\n",
    "\n",
    "\n",
    "# Train and evaluate models for all values of k\n",
    "train_errors, val_errors, test_errors = [], [], []\n",
    "for k in k_range:\n",
    "    model = KNeighborsClassifier(k).fit(X_train_smaller, y_train_smaller)\n",
    "    train_errors.append(1 - model.score(X_train_smaller, y_train_smaller))\n",
    "    val_errors.append(1 - model.score(X_val, y_val))\n",
    "    test_errors.append(1-model.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# Select model with lowest training error\n",
    "min_ind = np.argmin(np.array(val_errors))\n",
    "selected_k = np.array(k_range)[min_ind]\n",
    "selected_error = val_errors[min_ind]\n",
    "\n",
    "\n",
    "# Plot train- and test errors as well as which model (value of k) was selected\n",
    "fig = go.Figure([ \n",
    "    go.Scatter(name='Train Error', x=k_range, y=train_errors, mode='markers+lines', marker_color='rgb(152,171,150)'),\n",
    "    go.Scatter(name='Validation Error', x=k_range, y=val_errors, mode='markers+lines', marker_color='rgb(220,179,144)'),\n",
    "    go.Scatter(name='Test Error', x=k_range, y=test_errors, mode='markers+lines', marker_color='rgb(25,115,132)'), \n",
    "    go.Scatter(name='Selected Model', x=[selected_k], y=[selected_error], mode='markers', marker=dict(color='darkred', symbol=\"x\", size=10))\n",
    "]).update_layout(title=r\"$\\text{(2) }k\\text{-NN Errors - Selection By Minimal Error Over Validation Set}$\", \n",
    "                 xaxis_title=r\"$k\\text{ - Number of Neighbors}$\", \n",
    "                 yaxis_title=r\"$\\text{Error Value}$\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $k$-Fold Cross Validation\n",
    "\n",
    "In prepations for the next approach consider the following. Instead of using a single validation set, we can expand the above approach to use multiple validation sets. Then, we fit each model over the training set but evaluate its average performance over the different validation sets. We then select the model that achieved the lowest average error.\n",
    "\n",
    "The following code splits the training set into 4 portions: a training set and 3 validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training set into training and validation portions, and then \n",
    "# split validation portion into 3 validation sets\n",
    "msk = np.random.binomial(1, .7, X_train.shape[0]).astype(bool)\n",
    "X_train_smaller, y_train_smaller = X_train[msk], y_train[msk]\n",
    "\n",
    "validations = np.array_split(np.argwhere(~msk), 3)\n",
    "validations = [(X_train[v.ravel()], y_train[v.ravel()]) for v in validations]\n",
    "\n",
    "\n",
    "# Train and evaluate models for all values of k\n",
    "train_errors, test_errors, val_errors = [], [], [[] for _ in range(len(validations))]\n",
    "for k in k_range:\n",
    "    model = KNeighborsClassifier(k).fit(X_train_smaller, y_train_smaller)\n",
    "    train_errors.append(1-model.score(X_train_smaller, y_train_smaller))\n",
    "    test_errors.append(1-model.score(X_test, y_test))\n",
    "\n",
    "    for i in range(len(validations)): \n",
    "        val_errors[i].append(1 - model.score(*validations[i]))\n",
    "val_errors = np.array(val_errors)\n",
    "\n",
    "\n",
    "# Select model with lowest training error\n",
    "min_ind = np.argmin(val_errors.mean(axis=0))\n",
    "selected_k = np.array(k_range)[min_ind]\n",
    "selected_error = val_errors.mean(axis=0)[min_ind]\n",
    "mean, std = np.mean(val_errors, axis=0), np.std(val_errors, axis=0)\n",
    "\n",
    "\n",
    "# Select model with lowest training error\n",
    "go.Figure([\n",
    "    go.Scatter(name='Lower validation error', x=k_range, y=mean - 2*std, mode='lines', line=dict(color=\"lightgrey\"), showlegend=False, fill=None),\n",
    "    go.Scatter(name='Upper validation error', x=k_range, y=mean + 2*std, mode='lines', line=dict(color=\"lightgrey\"), showlegend=False, fill=\"tonexty\"), \n",
    "\n",
    "    go.Scatter(name='Train Error', x=k_range, y=train_errors, mode='markers+lines', marker_color='rgb(152,171,150)'),\n",
    "    go.Scatter(name='Mean Validation Error', x=k_range, y=mean, mode='markers+lines', marker_color='rgb(220,179,144)'),\n",
    "    go.Scatter(name='Test Error', x=k_range, y=test_errors, mode='markers+lines', marker_color='rgb(25,115,132)'), \n",
    "    go.Scatter(name='Selected Model', x=[selected_k], y=[selected_error], mode='markers', marker=dict(color='darkred', symbol=\"x\", size=10))\n",
    "]).update_layout(title=r\"$\\text{(3) }k\\text{-NN Errors - Selection By Minimal Error Over Validation Set}$\", \n",
    "                 xaxis_title=r\"$k\\text{ - Number of Neighbors}$\", \n",
    "                 yaxis_title=r\"$\\text{Error Value}$\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Figure 3, we can see the train- and test errors, as well as the results over the validation sets. These results are seen in two ways. The first is the average validation error achieved for each value of $k$ and is seen in the graph as the line of \"Mean Validation Error\". \n",
    "\n",
    "The second is the grey area seen in the plot. This is known as the confidence interval and is our estimation on where might the estimator be located (recall that the mean captures the first moment and the variance captures the second). This gives us a level of confidence in our prediction.\n",
    "\n",
    "The main problem with the approach above is that we have to put a side a lot of data which we cannot train over and just use for these independent validations. To adress this problem we instead use the Cross Validation approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors, test_errors = [], []\n",
    "for k in k_range:\n",
    "    model = KNeighborsClassifier(k).fit(X_train, y_train)\n",
    "    train_errors.append(1-model.score(X_train, y_train))\n",
    "    test_errors.append(1-model.score(X_test, y_test))\n",
    "\n",
    "param_grid = {'n_neighbors':k_range}\n",
    "knn_cv = GridSearchCV(KNeighborsClassifier(), param_grid, cv=3).fit(X_train, y_train)\n",
    "cv_errors = 1 - knn_cv.cv_results_[\"mean_test_score\"]\n",
    "std = knn_cv.cv_results_[\"std_test_score\"] \n",
    "    \n",
    "min_ind = np.argmin(np.array(cv_errors))\n",
    "selected_k = np.array(k_range)[min_ind]\n",
    "selected_error = cv_errors[min_ind]\n",
    "\n",
    "\n",
    "go.Figure([\n",
    "        go.Scatter(name='Lower CV Error CI', x=k_range, y=cv_errors - 2*std, mode='lines', line=dict(color=\"lightgrey\"), showlegend=False, fill=None),\n",
    "    go.Scatter(name='Upper CV Error CI', x=k_range, y=cv_errors + 2*std, mode='lines', line=dict(color=\"lightgrey\"), showlegend=False, fill=\"tonexty\"), \n",
    "    \n",
    "    go.Scatter(name=\"Train Error\", x=k_range, y=train_errors, mode='markers + lines', marker_color='rgb(152,171,150)'), \n",
    "    go.Scatter(name=\"CV Error\", x=k_range, y=cv_errors, mode='markers + lines', marker_color='rgb(220,179,144)'),\n",
    "    go.Scatter(name=\"Test Error\", x=k_range, y=test_errors, mode='markers + lines', marker_color='rgb(25,115,132)'), \n",
    "    go.Scatter(name='Selected Model', x=[selected_k], y=[selected_error], mode='markers', marker=dict(color='darkred', symbol=\"x\", size=10))])\\\n",
    ".update_layout(title=r\"$\\text{(4) }k\\text{-NN Errors - Selection By Cross-Validation}$\", \n",
    "                 xaxis_title=r\"$k\\text{ - Number of Neighbors}$\", \n",
    "                 yaxis_title=r\"$\\text{Error Value}$\").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}